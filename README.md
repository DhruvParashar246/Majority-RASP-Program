**Majority RASP → Transformer (Tracr + TorchLens)**
This project is an interpretability showcase, demonstrating how to "compile" a human-readable RASP (Recurrent Aggregating Sequence Processing) program into a standard transformer model using DeepMind's Tracr compiler. The model is trained to solve the "majority" problem: given a sequence of 0s and 1s, determine which element is the most frequent.

The project goes a step further by demonstrating how to use the PyTorch-based visualization tool TorchLens to inspect the compiled model's inner workings, providing a layer-by-layer view of the computation.

**Project Structure**
This repository contains all the necessary code and visualizations to reproduce the entire workflow, from RASP compilation to PyTorch visualization.

my_majority_program.py: Defines the majority RASP program and compiles it to a JAX/Haiku-based transformer. It also generates the initial high-level Tracr visualization (tracr_majority_graph.pdf).

export_tracr_params.py: A utility script that exports the learned weights and biases from the JAX model to a NumPy .npz file, ready for transfer to PyTorch.

tracr_transformer_pt.py: A custom PyTorch implementation of the transformer architecture, designed to mirror the structure of the Tracr-compiled model.

load_and_visualize_with_torchlens.py: The core script that loads the exported parameters into the PyTorch model, executes a forward pass, and generates the detailed computational graph using TorchLens (torchlens_majority_graph.pdf).

tracr_majority_params.npz: The NumPy archive containing the model parameters exported from the JAX model.

tracr_majority_graph.pdf: The initial, high-level computational graph of the model as generated directly by the Tracr compiler.

torchlens_majority_graph.pdf: The detailed, unrolled computational graph of the PyTorch model, showing every operation, as generated by TorchLens.

**Setup**
This project requires a few external libraries that are not included in this repository.

Create and activate a virtual environment:
python3 -m venv venv
source venv/bin/activate
Install project dependencies:
python -m pip install numpy jax torch torchlens --break-system-packages

Clone and install Tracr:
git clone https://github.com/google-deepmind/tracr.git
cd tracr
python -m pip install -e . --break-system-packages
cd .. # Go back to your project directory

Clone and install Haiku:
git clone https://github.com/deepmind/haiku.git
cd haiku
python -m pip install -e . --break-system-packages --use-pep517
cd .. # Go back to your project directory

**Usage**
Follow these steps in order to reproduce the results.

Compile the RASP program and generate the Tracr diagram:
python my_majority_program.py

Export the model parameters:
python export_tracr_params.py

Visualize with TorchLens:
python load_and_visualize_with_torchlens.py

### Results

This repository contains two key visualizations that highlight the different levels of abstraction in a compiled transformer.

The Tracr diagram shows the high-level transformer layers, demonstrating the overall architecture derived from the RASP program.
(tracr_majority_graph.pdf)

In contrast, the TorchLens diagram provides a fine-grained view of the same model's PyTorch computation graph, exposing all the sub-operations—like attention, softmax, and matrix multiplications—that implement the high-level logic.
(graph.gv.pdf)

Together, these visualizations offer a comprehensive look at how a high-level algorithm is translated into a low-level, executable neural network.

**Citation**
If you use Tracr in your work, please cite the original paper:
@article{lindner2023tracr,
  title    = {Tracr: Compiled Transformers as a Laboratory for Interpretability},
  author   = {Lindner, David and Kramár, J\'anos and Rahtz, Matthew and McGrath, Thomas and Mikulik, Vladimir},
  journal  = {arXiv preprint arXiv:2301.05062},
  year     = {2023}
}
